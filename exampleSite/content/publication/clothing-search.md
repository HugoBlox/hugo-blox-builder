+++
abstract = "We present a mobile visual clothing search system whereby a smart phone user can either choose a social networking photo or take a new photo of a person wearing clothing of interest and search for similar clothing in a retail database. From the query image, the person is detected, clothing is segmented, and clothing features are extracted and quantized. The information is sent from the phone client to a server, where the feature vector of the query image is used to retrieve similar clothing products from online databases. The phone's GPS location is used to re-rank results by retail store location. State of the art work focuses primarily on the recognition of a diverse range of clothing offline and pays little attention to practical applications. Evaluated on a challenging dataset, the system is relatively fast and achieves promising results."
abstract_short = "A mobile visual clothing search system is presented whereby a smart phone user can either choose a social networking image or capture a new photo of a person wearing clothing of interest and search for similar clothing in a large cloud-based ecommerce database. The phone's GPS location is used to re-rank results by retail store location, to inform the user of local stores where similar clothing items can be tried on."
authors = ["GA Cushen", "MS Nixon"]
date = "2013-07-01"
image = ""
image_preview = ""
math = true
publication = "In *International Conference on Multimedia and Expo Workshops (ICMEW)*, IEEE."
publication_short = "In *ICMEW*"
selected = true
title = "Mobile visual clothing search"
url_code = "#"
url_dataset = "#"
url_pdf = "http://eprints.soton.ac.uk/352095/1/Cushen-IMV2013.pdf"
url_project = "project/deep-learning/"
url_slides = "#"
url_video = "#"

[[url_custom]]
name = "Custom Link"
url = "http://www.example.org"

+++

More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code.
